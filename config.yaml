




# ====================================================================================
# General Parameters
# ====================================================================================

wandb_enabled: False
wandb_project_name: "Model-Misspecification"
wandb_exp_name: "Random Experiments"

early_stopping_enabled: True

device: "cuda"
noise_std: 0.
dh: 10
test_tries: 10 # How many test datasets to average results over / classical models to train

lambda_mle: 0.12 # value for the regularizing term of mle. has to be scaled by dataset size

# ====================================================================================
# Parameters for Classical Models
# ====================================================================================

num_iters_classical: 1
lr_classical: 0.001
dataset_size_classical: 50
weight_decay_classical: 1.2

# ====================================================================================
# Parameters for In-Context Models
# ====================================================================================

num_iters_in_context: 1000
lr_in_context: 0.00001
dataset_size_in_context: 128
dataset_amount: 100
weight_decay_in_context: 12.0
batch_size_in_context: 100